{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivan8Garcia/Proyecto_NoCountry/blob/main/validacionPKL_OXXN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h3x-cbBNSvC",
        "outputId": "76598d61-597e-4a0c-f67f-63812fb44c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# conectar a Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SvtSFUOzNvNJ",
        "outputId": "72abdc53-624f-40c2-84e9-56f0cb44ee4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas Drive\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Hackaton/Datos/flights_sample_3m.csv'"
      ],
      "metadata": {
        "id": "umzG-rSENZv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Carga el modelo ONNX\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Hackaton/Datos/flight_delay_model.onnx\"\n",
        "onnx_model = onnx.load(model_path)\n",
        "\n",
        "# Imprime información básica del modelo\n",
        "print(\"Versión del modelo ONNX:\", onnx_model.ir_version)\n",
        "print(\"Productor:\", onnx_model.producer_name)\n",
        "print(\"Versión del productor:\", onnx_model.producer_version)\n",
        "print(\"Dominio:\", onnx_model.domain)\n",
        "print(\"Versión del modelo:\", onnx_model.model_version)\n",
        "\n",
        "# Inspecciona los inputs (entradas)\n",
        "print(\"\\n--- Inputs ---\")\n",
        "for input_tensor in onnx_model.graph.input:\n",
        "    print(f\"Nombre: {input_tensor.name}\")\n",
        "    print(f\"Tipo: {input_tensor.type}\")\n",
        "    # Para ver la forma (shape), si está disponible\n",
        "    if input_tensor.type.tensor_type.shape:\n",
        "        shape = [dim.dim_value if dim.dim_value else 'None' for dim in input_tensor.type.tensor_type.shape.dim]\n",
        "        print(f\"Forma: {shape}\")\n",
        "    print(\"---\")\n",
        "\n",
        "# Inspecciona los outputs (salidas)\n",
        "print(\"\\n--- Outputs ---\")\n",
        "for output_tensor in onnx_model.graph.output:\n",
        "    print(f\"Nombre: {output_tensor.name}\")\n",
        "    print(f\"Tipo: {output_tensor.type}\")\n",
        "    if output_tensor.type.tensor_type.shape:\n",
        "        shape = [dim.dim_value if dim.dim_value else 'None' for dim in output_tensor.type.tensor_type.shape.dim]\n",
        "        print(f\"Forma: {shape}\")\n",
        "    print(\"---\")\n",
        "\n",
        "# Inspecciona el grafo (nodos y operaciones)\n",
        "print(\"\\n--- Grafo (primeros 10 nodos) ---\")\n",
        "for i, node in enumerate(onnx_model.graph.node[:10]):  # Limita a 10 para no saturar\n",
        "    print(f\"Nodo {i}: {node.op_type} - Inputs: {node.input} - Outputs: {node.output}\")\n",
        "\n",
        "# Verifica si el modelo es válido\n",
        "print(\"\\n--- Verificación ---\")\n",
        "try:\n",
        "    onnx.checker.check_model(onnx_model)\n",
        "    print(\"El modelo ONNX es válido.\")\n",
        "except onnx.onnx_cpp2py_export.checker.ValidationError as e:\n",
        "    print(f\"Error de validación: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSr0SfjCNvvM",
        "outputId": "909e4647-69ae-452f-ebef-f70d79b712a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión del modelo ONNX: 10\n",
            "Productor: skl2onnx\n",
            "Versión del productor: 1.19.1\n",
            "Dominio: ai.onnx\n",
            "Versión del modelo: 0\n",
            "\n",
            "--- Inputs ---\n",
            "Nombre: DEP_HOUR\n",
            "Tipo: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: ['None', 1]\n",
            "---\n",
            "Nombre: DAY_OF_WEEK\n",
            "Tipo: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: ['None', 1]\n",
            "---\n",
            "Nombre: IS_WEEKEND\n",
            "Tipo: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: ['None', 1]\n",
            "---\n",
            "Nombre: DISTANCE\n",
            "Tipo: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: ['None', 1]\n",
            "---\n",
            "Nombre: TAXI_OUT\n",
            "Tipo: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: ['None', 1]\n",
            "---\n",
            "Nombre: AIRLINE\n",
            "Tipo: tensor_type {\n",
            "  elem_type: 8\n",
            "  shape {\n",
            "    dim {\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: ['None', 1]\n",
            "---\n",
            "\n",
            "--- Outputs ---\n",
            "Nombre: output_label\n",
            "Tipo: tensor_type {\n",
            "  elem_type: 7\n",
            "  shape {\n",
            "    dim {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: ['None']\n",
            "---\n",
            "Nombre: output_probability\n",
            "Tipo: sequence_type {\n",
            "  elem_type {\n",
            "    map_type {\n",
            "      key_type: 7\n",
            "      value_type {\n",
            "        tensor_type {\n",
            "          elem_type: 1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Forma: []\n",
            "---\n",
            "\n",
            "--- Grafo (primeros 10 nodos) ---\n",
            "Nodo 0: Concat - Inputs: ['DEP_HOUR', 'DAY_OF_WEEK', 'IS_WEEKEND', 'DISTANCE', 'TAXI_OUT'] - Outputs: ['merged_columns']\n",
            "Nodo 1: Gather - Inputs: ['AIRLINE', 'AIRLINE0'] - Outputs: ['AIRLINE01']\n",
            "Nodo 2: OneHotEncoder - Inputs: ['AIRLINE01'] - Outputs: ['AIRLINE01out']\n",
            "Nodo 3: Reshape - Inputs: ['AIRLINE01out', 'shape_tensor'] - Outputs: ['variable']\n",
            "Nodo 4: Concat - Inputs: ['variable', 'merged_columns'] - Outputs: ['transformed_column']\n",
            "Nodo 5: TreeEnsembleClassifier - Inputs: ['transformed_column'] - Outputs: ['label', 'probabilities']\n",
            "Nodo 6: Cast - Inputs: ['label'] - Outputs: ['output_label']\n",
            "Nodo 7: ZipMap - Inputs: ['probabilities'] - Outputs: ['output_probability']\n",
            "\n",
            "--- Verificación ---\n",
            "El modelo ONNX es válido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Estructura Archivo Original PKL"
      ],
      "metadata": {
        "id": "hO1jsyakQ20I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib  # Usa joblib en lugar de pickle, ya que sklearn lo recomienda para modelos\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Ruta del archivo .pkl (joblib puede cargar archivos .pkl)\n",
        "path_org = \"/content/drive/MyDrive/Colab Notebooks/Hackaton/Datos/flight_delay_model_backend.pkl\"\n",
        "\n",
        "# Carga el modelo desde el archivo .pkl usando joblib\n",
        "try:\n",
        "    model = joblib.load(path_org)\n",
        "    print(\"Modelo cargado exitosamente desde el archivo .pkl.\")\n",
        "\n",
        "    # Imprime información básica del modelo (adaptado, ya que .pkl no tiene versión/productor como ONNX)\n",
        "    print(f\"Tipo de modelo: {type(model)}\")\n",
        "    if hasattr(model, '__version__'):\n",
        "        print(f\"Versión de sklearn (si aplica): {model.__version__}\")\n",
        "    else:\n",
        "        print(\"Versión no disponible en el modelo.\")\n",
        "\n",
        "    # Extrae y imprime las columnas esperadas (basado en el preprocessor del Pipeline)\n",
        "    if hasattr(model, 'named_steps_') and 'preprocessor' in model.named_steps_:\n",
        "        preprocessor = model.named_steps_['preprocessor']\n",
        "        if hasattr(preprocessor, 'transformers_'):\n",
        "            # Asumiendo que el primer transformer es 'cat' y el segundo 'num' (como en tu output esperado)\n",
        "            cat_features = preprocessor.transformers_[0][2]  # Lista de columnas categóricas\n",
        "            num_features = preprocessor.transformers_[1][2]  # Lista de columnas numéricas\n",
        "            expected_columns = cat_features + num_features\n",
        "            print(f\"Columnas esperadas: {expected_columns}\")\n",
        "        else:\n",
        "            print(\"Columnas esperadas: No disponibles (preprocessor no tiene transformers_).\")\n",
        "    else:\n",
        "        print(\"Columnas esperadas: No disponibles (no es un Pipeline con preprocessor).\")\n",
        "\n",
        "    # Imprime el modelo completo (Pipeline)\n",
        "    print(f\"Modelo (Pipeline): {model}\")\n",
        "\n",
        "    # Imprime los pasos del Pipeline\n",
        "    print(f\"Pasos del Pipeline: {model.steps}\")\n",
        "\n",
        "    # Inspecciona los inputs (entradas) - Basado en el Pipeline esperado\n",
        "    print(\"\\n--- Inputs ---\")\n",
        "    if hasattr(model, 'feature_names_in_'):\n",
        "        print(f\"Nombre: features\")\n",
        "        print(f\"Tipo: tensor (asumido float64 o similar)\")\n",
        "        print(f\"Forma: [None, {len(model.feature_names_in_)}]  # (n_samples, n_features)\")\n",
        "        print(f\"Nombres de features: {list(model.feature_names_in_)}\")\n",
        "    elif hasattr(model, 'steps') and 'preprocessor' in dict(model.steps):\n",
        "        # Extrae columnas del preprocessor si es un ColumnTransformer\n",
        "        preprocessor = model.named_steps_['preprocessor']\n",
        "        if hasattr(preprocessor, 'get_feature_names_out'):\n",
        "            # Intenta obtener nombres de features transformadas\n",
        "            try:\n",
        "                feature_names = list(preprocessor.get_feature_names_out())\n",
        "                print(f\"Nombre: features\")\n",
        "                print(f\"Tipo: tensor (asumido float64 o similar)\")\n",
        "                print(f\"Forma: [None, {len(feature_names)}]  # (n_samples, n_features)\")\n",
        "                print(f\"Nombres de features (transformadas): {feature_names}\")\n",
        "            except:\n",
        "                print(\"Nombre: features\")\n",
        "                print(\"Tipo: tensor (asumido float64 o similar)\")\n",
        "                print(\"Forma: [None, n_features]  # n_features desconocido\")\n",
        "                print(\"Nota: No se pudieron obtener nombres de features transformadas.\")\n",
        "        else:\n",
        "            print(\"Nombre: features\")\n",
        "            print(\"Tipo: tensor (asumido float64 o similar)\")\n",
        "            print(\"Forma: [None, n_features]  # n_features desconocido sin info adicional\")\n",
        "            print(\"Nota: Los nombres de features no están disponibles en este modelo .pkl.\")\n",
        "    else:\n",
        "        print(\"Nombre: features\")\n",
        "        print(\"Tipo: tensor (asumido float64 o similar)\")\n",
        "        print(\"Forma: [None, n_features]  # n_features desconocido sin info adicional\")\n",
        "        print(\"Nota: Los nombres de features no están disponibles en este modelo .pkl.\")\n",
        "    print(\"---\")\n",
        "\n",
        "    # Inspecciona los outputs (salidas) - Basado en el clasificador\n",
        "    print(\"\\n--- Outputs ---\")\n",
        "    print(f\"Nombre: predictions\")\n",
        "    print(f\"Tipo: tensor (int o float, dependiendo del tipo de modelo)\")\n",
        "    if hasattr(model, 'classes_'):\n",
        "        # Para modelos de clasificación\n",
        "        print(f\"Forma: [None, {len(model.classes_)}]  # (n_samples, n_classes) para clasificación\")\n",
        "        print(f\"Clases: {list(model.classes_)}\")\n",
        "    else:\n",
        "        # Para modelos de regresión o otros\n",
        "        print(\"Forma: [None, 1]  # (n_samples, 1) para regresión u otros\")\n",
        "        print(\"Nota: No hay clases definidas (posiblemente un modelo de regresión).\")\n",
        "    print(\"---\")\n",
        "\n",
        "    # Inspecciona el \"grafo\" (nodos y operaciones) - Adaptado para modelos .pkl\n",
        "    print(\"\\n--- Grafo (tipo de modelo y pasos si es un pipeline) ---\")\n",
        "    print(f\"Tipo de modelo: {type(model)}\")\n",
        "    if hasattr(model, 'steps'):\n",
        "        # Si es un Pipeline de scikit-learn, inspecciona los pasos\n",
        "        for i, (name, step) in enumerate(model.steps[:10]):  # Limita a 10 para no saturar\n",
        "            print(f\"Paso {i}: {name} - Tipo: {type(step)}\")\n",
        "            # Imprime detalles adicionales si es posible\n",
        "            if hasattr(step, 'transformers_') and name == 'preprocessor':\n",
        "                print(f\"  Detalles del preprocessor: {step}\")\n",
        "            elif hasattr(step, 'estimators_') or hasattr(step, 'base_estimator_'):\n",
        "                print(f\"  Detalles del clasificador: {step}\")\n",
        "    else:\n",
        "        print(\"No hay pasos de pipeline disponibles (modelo simple).\")\n",
        "        print(\"Nota: Los modelos .pkl no tienen un grafo explícito como ONNX; esto es una representación simplificada.\")\n",
        "\n",
        "    # Verifica si el modelo es válido (solo carga exitosa)\n",
        "    print(\"\\n--- Verificación ---\")\n",
        "    try:\n",
        "        # Para scikit-learn, una verificación básica es intentar acceder a un atributo clave\n",
        "        if hasattr(model, 'predict'):\n",
        "            print(\"El modelo .pkl parece válido (tiene método predict).\")\n",
        "        else:\n",
        "            print(\"Advertencia: El modelo no tiene método predict; podría no ser un modelo estándar.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error de verificación: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar o inspeccionar el modelo: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO2nUgehRyBM",
        "outputId": "d4c47d45-e973-4a38-e280-9ae197060ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente desde el archivo .pkl.\n",
            "Tipo de modelo: <class 'dict'>\n",
            "Versión no disponible en el modelo.\n",
            "Columnas esperadas: No disponibles (no es un Pipeline con preprocessor).\n",
            "Modelo (Pipeline): {'model': Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('cat',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore',\n",
            "                                                                sparse_output=False),\n",
            "                                                  ['AIRLINE']),\n",
            "                                                 ('num', 'passthrough',\n",
            "                                                  ['DEP_HOUR', 'DAY_OF_WEEK',\n",
            "                                                   'IS_WEEKEND', 'DISTANCE',\n",
            "                                                   'TAXI_OUT'])])),\n",
            "                ('classifier',\n",
            "                 RandomForestClassifier(class_weight='balanced', max_depth=15,\n",
            "                                        n_jobs=-1, random_state=42))]), 'expected_columns': ['DEP_HOUR', 'DAY_OF_WEEK', 'IS_WEEKEND', 'DISTANCE', 'TAXI_OUT', 'AIRLINE']}\n",
            "Error al cargar o inspeccionar el modelo: 'dict' object has no attribute 'steps'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Análisis"
      ],
      "metadata": {
        "id": "YeIPpG-UUPwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Estructura General del Modelo"
      ],
      "metadata": {
        "id": "ynQCg2oSURdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   ONNX: Es una representación estandarizada del modelo (convertida\n",
        "desde sklearn usando skl2onnx). Incluye metadatos como versión, productor (skl2onnx), y un grafo computacional que describe las operaciones paso a paso.\n",
        "*   PKL: Es el modelo original de scikit-learn (sklearn), serializado como un objeto Python. Muestra la estructura del Pipeline directamente, con sus pasos y configuraciones.\n",
        "*   Equivalencia: Ambos describen el mismo flujo: un preprocesamiento de datos seguido de un clasificador. El ONNX es esencialmente una \"traducción\" del PKL a un formato interoperable (ONNX), pero el núcleo (preprocesamiento + clasificación) es idéntico."
      ],
      "metadata": {
        "id": "BbvkY2e9UVaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Inputs (Entradas)"
      ],
      "metadata": {
        "id": "kMaMn5ULUikQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   ONNX: Lista 6 inputs explícitos con nombres (DEP_HOUR, DAY_OF_WEEK, IS_WEEKEND, DISTANCE, TAXI_OUT, AIRLINE). Cada uno tiene un tipo (tensor_type con elem_type 1 para numéricos/float o 8 para strings/categóricos) y forma ['None', 1] (indicando que acepta un lote de muestras, cada una con 1 valor por feature).\n",
        "*   PKL: Muestra \"Columnas esperadas\" como una lista: ['DEP_HOUR', 'DAY_OF_WEEK', 'IS_WEEKEND', 'DISTANCE', 'TAXI_OUT', 'AIRLINE']. Esto coincide exactamente con los inputs del ONNX.\n",
        "*   Equivalencia: Los inputs son los mismos 6 features. En el PKL, se derivan del ColumnTransformer en el preprocessor (que maneja categóricas y numéricas). El ONNX los representa de forma más detallada (con tipos y formas), pero son idénticos en contenido."
      ],
      "metadata": {
        "id": "qS_jXRRCUpkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Outputs (Salidas)"
      ],
      "metadata": {
        "id": "572M_dJ2U3nC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   ONNX: Dos outputs: output_label (etiqueta de clase, tipo tensor_type con elem_type 7 para int64, forma ['None']) y output_probability (probabilidades por clase, tipo sequence_type con map_type para un diccionario clave-valor).\n",
        "*   PKL: No muestra outputs explícitos en el output proporcionado, pero el RandomForestClassifier (clasificador de bosque aleatorio) produce predicciones de clase y probabilidades por defecto en sklearn. El Pipeline implica que el output final es la predicción del clasificador.\n",
        "*   Equivalencia: Ambos generan las mismas salidas lógicas (etiqueta + probabilidades). El ONNX las detalla más (con tipos ONNX), mientras que el PKL las asume como parte del comportamiento estándar del clasificador. Si ejecutas predicciones en el PKL, obtendrías predict() (etiquetas) y predict_proba() (probabilidades), que coinciden con el ONNX."
      ],
      "metadata": {
        "id": "XtGVHS6hU5Z6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Grafo/Operaciones Internas (Procesamiento)"
      ],
      "metadata": {
        "id": "MN0m41GTVBi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   ONNX: Describe un grafo con 8 nodos (operaciones secuenciales):\n",
        "*   Nodos 0-4: Preprocesamiento (e.g., Concat para combinar numéricas, OneHotEncoder para AIRLINE, Reshape para ajustar formas).\n",
        "*   Nodos 5-7: Clasificación (TreeEnsembleClassifier para el RandomForest, Cast y ZipMap para formatear outputs).\n",
        "Esto refleja cómo skl2onnx convierte el Pipeline de sklearn a operaciones ONNX.\n",
        "\n",
        "2.   PKL: Muestra el Pipeline con dos pasos principales:\n",
        "*   preprocessor: Un ColumnTransformer que aplica OneHotEncoder a ['AIRLINE'] (categórica) y 'passthrough' a las numéricas (['DEP_HOUR', 'DAY_OF_WEEK', 'IS_WEEKEND', 'DISTANCE', 'TAXI_OUT']).\n",
        "*   classifier: Un RandomForestClassifier con parámetros específicos (e.g., max_depth=15, class_weight='balanced').\n",
        "\n",
        "3.   Equivalencia: El grafo del ONNX es una descomposición detallada del Pipeline del PKL. Por ejemplo:\n",
        "*   El Concat y OneHotEncoder en ONNX corresponden al ColumnTransformer en PKL.\n",
        "*   El TreeEnsembleClassifier en ONNX es el RandomForestClassifier en PKL.\n",
        "*   Ambos manejan las mismas transformaciones: codificación one-hot para AIRLINE y paso directo para numéricas, seguido de clasificación."
      ],
      "metadata": {
        "id": "ptgLmkQ0VDDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Otras Consideraciones"
      ],
      "metadata": {
        "id": "kJPqJF18WADJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Metadatos: El ONNX incluye versiones y dominio (específicos de ONNX), mientras que el PKL muestra el tipo de objeto sklearn. Esto no afecta la equivalencia funcional.\n",
        "2.   Validación: Ambos modelos son \"válidos\" en sus contextos (ONNX pasa onnx.checker, PKL se carga correctamente).\n",
        "3.   Diferencias en Representación: El ONNX es más \"bajo nivel\" (grafo de operaciones) y portable (puedes ejecutarlo en otros frameworks), mientras que el PKL es el modelo sklearn nativo (más fácil de inspeccionar en Python). Pero funcionalmente, producen los mismos resultados para los mismos inputs.\n",
        "4.   Prueba de Equivalencia: Si cargas datos de prueba y predices con ambos (usando onnxruntime para ONNX y joblib para PKL), las salidas deberían ser idénticas (o muy cercanas, considerando posibles diferencias numéricas menores en la conversión)."
      ],
      "metadata": {
        "id": "myU5-2RBWD1n"
      }
    }
  ]
}