{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNygzsdk47MNQnCH9D0SuTw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivan8Garcia/Proyecto_NoCountry/blob/main/Vuelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NVQCwXiCtH0X",
        "outputId": "0ca88df9-baa0-41c5-d750-921324043739"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/flight_delays.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2118929803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdatos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/flight_delays.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/flight_delays.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "datos=pd.read_csv(\"/content/flight_delays.csv\")\n",
        "datos.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "h5eZH23-vxFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.isnull().sum()"
      ],
      "metadata": {
        "id": "44tqBVVRwEmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.fillna(0,inplace=True)"
      ],
      "metadata": {
        "id": "3J2eM3HwwMdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.isnull().sum()"
      ],
      "metadata": {
        "id": "iQqHOjhhwUmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head()"
      ],
      "metadata": {
        "id": "RwVrqRbRwrD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ELIMINACION DE COLUMNAS PARA MODELO MVP, SOLO NECESITAREMOS \"Aerolínea\",\"Origen\", \"Destino\", \"Hora_salida_programada\", \"Hora_llegada_programada\",\"Retraso\",\"Distancia\" y crear la columna binaria \"Retrasado\"."
      ],
      "metadata": {
        "id": "SKdNdPeHx0no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Re-read data to ensure this cell works with the original columns\n",
        "# This effectively resets 'datos' to the state before other preprocessing cells.\n",
        "datos = pd.read_csv(\"/content/flight_delays.csv\")\n",
        "datos.fillna(0, inplace=True) # Apply previous fillna logic\n",
        "\n",
        "# Select and rename columns as per original intent of this cell, plus ScheduledArrival for user's request\n",
        "datos = datos[['Airline', 'Origin', 'Destination', 'ScheduledDeparture','ScheduledArrival','Distance','DelayMinutes']].copy()\n",
        "datos = datos.rename(columns={'Airline': 'Aerolínea',\n",
        "                              'Origin': 'Origen',\n",
        "                              'Destination': 'Destino',\n",
        "                              'ScheduledDeparture': 'Fecha/Hora_Salida',\n",
        "                              'ScheduledArrival': 'Fecha/Hora_Llegada_Programada',\n",
        "                              'Distance' : 'Distancia',\n",
        "                              'DelayMinutes': 'Retraso_minutos'})\n",
        "\n",
        "# Process 'Fecha/Hora_Salida' (original 'ScheduledDeparture')\n",
        "datos['Fecha/Hora_Salida'] = pd.to_datetime(datos['Fecha/Hora_Salida'])\n",
        "\n",
        "# Add day of the week\n",
        "datos['Dia_semana_temp'] = datos['Fecha/Hora_Salida'].dt.day_name()\n",
        "spanish_days = {\n",
        "    'Monday': 'Lunes', 'Tuesday': 'Martes', 'Wednesday': 'Miércoles',\n",
        "    'Thursday': 'Jueves', 'Friday': 'Viernes', 'Saturday': 'Sábado', 'Sunday': 'Domingo'\n",
        "}\n",
        "datos['Dia_semana'] = datos['Dia_semana_temp'].map(spanish_days)\n",
        "datos.drop('Dia_semana_temp', axis=1, inplace=True)\n",
        "\n",
        "# Extract 'Fecha' and 'Hora_salida'\n",
        "datos['Fecha'] = datos['Fecha/Hora_Salida'].dt.date\n",
        "datos['Hora_salida'] = datos['Fecha/Hora_Salida'].dt.time\n",
        "datos.drop('Fecha/Hora_Salida', axis=1, inplace=True) # Drop the original combined column\n",
        "\n",
        "# Process 'Fecha/Hora_Llegada_Programada' (original 'ScheduledArrival') as requested\n",
        "# Convert to datetime first\n",
        "datos['Fecha/Hora_Llegada_Programada'] = pd.to_datetime(datos['Fecha/Hora_Llegada_Programada'])\n",
        "\n",
        "# Extract the time part into a new column, e.g., 'Hora_llegada'\n",
        "datos['Hora_llegada'] = datos['Fecha/Hora_Llegada_Programada'].dt.time\n",
        "\n",
        "# \"elimines la fecha\" from 'Fecha/Hora_Llegada_Programada'.\n",
        "# This means we either drop the column or make it store only time.\n",
        "# If we keep the column and make it store only time, it becomes redundant with 'Hora_llegada'.\n",
        "# So, it's best to drop 'Fecha/Hora_Llegada_Programada' now that its time part is extracted.\n",
        "datos.drop('Fecha/Hora_Llegada_Programada', axis=1, inplace=True)\n",
        "\n",
        "# Create the binary 'retrasado' column based on 'Retraso_minutos'\n",
        "datos['Retrasado'] = (datos['Retraso_minutos'] > 15).astype(int)\n",
        "\n",
        "# Ensure the requested column order, placing 'Retraso_minutos' and 'Retrasado' after 'Hora'\n",
        "datos = datos[['Aerolínea', 'Origen', 'Destino','Distancia', 'Dia_semana', 'Fecha', 'Hora_salida','Hora_llegada', 'Retraso_minutos', 'Retrasado']]\n",
        "\n",
        "datos.head()"
      ],
      "metadata": {
        "id": "g2xdQk0MaL2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.drop(\"Fecha\",axis=1,inplace=True)\n",
        "datos.drop(\"Dia_semana\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "ANucqM6xUWn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head()"
      ],
      "metadata": {
        "id": "l85vW5HOSEmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "1vwYrH-GDWXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccd83bd1"
      },
      "source": [
        "# Convert 'Hora' from datetime.time object to a float representing total hours\n",
        "datos['Hora_salida'] = datos['Hora_salida'].apply(lambda x: x.hour + x.minute/60 + x.second/3600)\n",
        "datos['Hora_llegada'] = datos['Hora_llegada'].apply(lambda x: x.hour + x.minute/60 + x.second/3600)\n",
        "\n",
        "datos.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head(3)"
      ],
      "metadata": {
        "id": "s5UV5Eapaw5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.tail(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MJ-ftE0Ea5c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#variables categoricas\n",
        "datos.describe(include=\"O\")"
      ],
      "metadata": {
        "id": "MCCPPZ4x7ovy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VB4GuKhO78tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_delay= datos.groupby(\"Aerolínea\")[\"Retraso_minutos\"].mean().reset_index()\n",
        "sns.barplot(x=\"Aerolínea\",y=\"Retraso_minutos\",data=avg_delay)\n",
        "plt.title(\"Compañias Aereas vs Retraso promedio\")\n",
        "plt.xlabel(\"Compañias Aereas\")\n",
        "plt.ylabel(\"Retraso promedio en minutos\")\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(data=datos,x=\"Aerolínea\")\n",
        "plt.title(\"Numero de vuelos por compañia aerea\")\n",
        "plt.xlabel(\"Compañia Aerea\")\n",
        "plt.ylabel(\"Numero de vuelos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MTm3DVvp7-ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order=datos[\"Aerolínea\"].value_counts().index\n",
        "sns.countplot(data=datos,x=\"Aerolínea\",order=order)\n",
        "plt.title(\"Numero de vuelos por Aerolínea\")\n",
        "plt.xticks(rotation=70)\n",
        "plt.xlabel(\"Compañia\")\n",
        "plt.ylabel(\"Numero de vuelos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2L9jLHSK-H5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delay_counts = datos['Retrasado'].value_counts(normalize=True)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(delay_counts, labels=['No Retrasado (0)', 'Retrasado (1)'], autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#ff9999'])\n",
        "plt.title('Proporción de Vuelos Retrasados vs. No Retrasados')\n",
        "plt.ylabel('') # Hide the default 'Retrasado' label on the y-axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lcj1I_sSEfzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Metodo get_dummies**"
      ],
      "metadata": {
        "id": "0Zx55JKV8VN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Todas estas columnas son categoricas (OBJ), para que se puedan hacer buenos modelos hay que codificarlas\n",
        "#categoricas= [\"Aerolínea\",\"Origen\",\"Destino\"]\n",
        "\n",
        "#pd.get_dummies(data=datos,columns=categoricas,dtype=int).head(3)"
      ],
      "metadata": {
        "id": "eGfgZVgOchTT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datos_codificados=pd.get_dummies(data=datos,columns=categoricas,dtype=int)\n",
        "#datos_codificados.sample(3)"
      ],
      "metadata": {
        "id": "ApjFgoY_dTNM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datos_codificados.info()"
      ],
      "metadata": {
        "id": "Mne_CJCpefK_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df=datos_codificados\n",
        "#df"
      ],
      "metadata": {
        "id": "IU3ycRDChEix",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**OneHotEnconder**"
      ],
      "metadata": {
        "id": "si-V9dNMCoH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "8pxeDMw5qqR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅ Definir X e y, observese que se excluye Retraso_minutos**"
      ],
      "metadata": {
        "id": "gx213vAn05-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable objetivo\n",
        "y = datos[\"Retrasado\"]\n",
        "\n",
        "# Variables predictoras\n",
        "X = datos[[\n",
        "    \"Aerolínea\",\n",
        "    \"Origen\",\n",
        "    \"Destino\",\n",
        "    \"Distancia\",\n",
        "    \"Hora_salida\",\n",
        "    \"Hora_llegada\"\n",
        "]]\n"
      ],
      "metadata": {
        "id": "5jaOj8twqqOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅  Crear variables cíclicas para las horas**"
      ],
      "metadata": {
        "id": "VxJNO8kj1ViE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cyclical_encode_hour(datos, col_name):\n",
        "    datos[col_name + \"_sin\"] = np.sin(2 * np.pi * datos[col_name] / 24)\n",
        "    datos[col_name + \"_cos\"] = np.cos(2 * np.pi * datos[col_name] / 24)\n",
        "    return datos\n",
        "\n",
        "datos = cyclical_encode_hour(datos, \"Hora_salida\")\n",
        "datos = cyclical_encode_hour(datos, \"Hora_llegada\")\n",
        "\n",
        "# Eliminamos columnas originales de hora\n",
        "datos = datos.drop(columns=[\"Hora_salida\", \"Hora_llegada\"])\n"
      ],
      "metadata": {
        "id": "cXSCfp9vqqLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head()"
      ],
      "metadata": {
        "id": "uNf0AUiCsecz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅  Separar columnas categóricas y numéricas**"
      ],
      "metadata": {
        "id": "bOXKETTn1neN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = [\"Aerolínea\", \"Origen\", \"Destino\"]\n",
        "\n",
        "numeric_features = [\n",
        "    \"Distancia\",\n",
        "    \"Hora_salida_sin\",\n",
        "    \"Hora_salida_cos\",\n",
        "    \"Hora_llegada_sin\",\n",
        "    \"Hora_llegada_cos\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "aPnBqJK1qqIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅  Transformador de columnas (One-Hot incluido)**"
      ],
      "metadata": {
        "id": "v_9v1aQk1vbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "        (\"num\", \"passthrough\", numeric_features)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "jiBQSNefqqFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅  Definir el modelo (puedes cambiarlo si quieres)**"
      ],
      "metadata": {
        "id": "0eKJPo6213hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "BXSPgPcdqqCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅  Crear Pipeline completo**"
      ],
      "metadata": {
        "id": "jFHezcsC1-Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", model)\n",
        "])\n"
      ],
      "metadata": {
        "id": "rCi-TWPXqp_r"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅ Train/Test Split**"
      ],
      "metadata": {
        "id": "w52glOJ62GSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "TFaeKXpQqp6W"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅ Entrenamiento**"
      ],
      "metadata": {
        "id": "8sAV7Ld_2Lg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "_bqpIAjMrQCz",
        "outputId": "88d22290-bd18-43f8-a5e9-3d9ba0c4d271"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A given column is not a column of the dataframe",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Hora_salida_sin'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_indexing.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mcol_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Hora_salida_sin'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-533357445.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0mtransformer_to_input_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_indexing.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A given column is not a column of the dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**✅ Evaluacion**"
      ],
      "metadata": {
        "id": "TcJF8VcW2UXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "SCbEpDNerQAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSw5yTBPrP9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBBHF4X1rP6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = datos.drop('Retrasado', axis = 1)\n",
        "y = datos['Retrasado']\n"
      ],
      "metadata": {
        "id": "oYA1tLHRDB4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categoricas= [\"Aerolínea\",\"Origen\",\"Destino\"]\n",
        "\n",
        "one_hot_enc = make_column_transformer(\n",
        "    (OneHotEncoder(handle_unknown='ignore'),\n",
        "    categoricas),\n",
        "    remainder='passthrough',\n",
        "    sparse_threshold=0,\n",
        "    force_int_remainder_cols=False)\n",
        "\n",
        "datos = one_hot_enc.fit_transform(datos)\n",
        "datos = pd.DataFrame(datos, columns=one_hot_enc.get_feature_names_out())\n",
        "datos"
      ],
      "metadata": {
        "id": "f7e1fYTEChOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas = X.columns\n",
        "X = one_hot_enc.fit_transform(X)\n",
        "X = pd.DataFrame(X, columns=one_hot_enc.get_feature_names_out(columnas))"
      ],
      "metadata": {
        "id": "btCwiGBuChLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y"
      ],
      "metadata": {
        "id": "A4XwGvnyChIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y,  random_state = 42)"
      ],
      "metadata": {
        "id": "p-KHrPPdChGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "jZsX4T53Ebes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf= RandomForestClassifier(max_depth = 10, random_state=5)\n",
        "rf.fit(pd.DataFrame(X_train), y_train)\n",
        "rf.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "lBSuFp58ChDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8VuteTMChAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CzzEQHrCg9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define X and y specifically for the classification task\n",
        "# X should exclude both 'Retraso_minutos' (which is the regression target)\n",
        "# and 'Retrasado' (which is the classification target).\n",
        "X = df.drop([\"Retrasado\",\"Retraso_minutos\"], axis=1)\n",
        "y = df[\"Retraso_minutos\"]\n",
        "\n",
        "# Split the data for the classification task\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Instanciar el DummyClassifier\n",
        "# Usamos 'most_frequent' porque es el baseline más común: siempre predice la clase mayoritaria.\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "# 2. \"Entrenar\" el modelo (aquí solo aprende cuál es la clase más frecuente)\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "\n",
        "# 3. Realizar predicciones sobre el set de prueba\n",
        "y_pred = dummy_clf.predict(X_test)\n",
        "\n",
        "# 4. Evaluar el rendimiento\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy del Baseline: {accuracy:.2f}\")\n",
        "\n",
        "# 5. Ver el reporte detallado\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['No Retrasado', 'Retrasado'], zero_division=0))"
      ],
      "metadata": {
        "id": "SrnT0srnZxV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_WSs6ne98qib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#primero separamos nuestras columnas para tener las columnas de prueba y entrenamiento\n",
        "X= df.drop([\"Retrasado\"],axis=1)\n",
        "y=df[\"Retrasado\"]\n",
        "\n",
        "#segundo,empezaremos a segmentar nuestras X_train,etc...\n",
        "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "baseline=DummyRegressor()\n",
        "baseline.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "g77klQ5x8t1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora vamos a evaluar el modelo usando metricas\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "\n",
        "y_pred_dummy=baseline.predict(X_test)\n",
        "\n",
        "def calcular_regresion (y_test,y_pred):\n",
        "  rmse=mean_squared_error(y_test,y_pred)\n",
        "  mae=mean_absolute_error(y_test,y_pred)\n",
        "  r2= r2_score(y_test,y_pred)\n",
        "  metricas={\n",
        "      \"RMSE\":round(rmse**(1/2),4),\n",
        "      \"MAE\":round(mae,4),\n",
        "      \"R2\":round(r2,4)\n",
        "  }\n",
        "  return metricas"
      ],
      "metadata": {
        "id": "uJdozW1x9oAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_baseline=calcular_regresion(y_test,y_pred_dummy)\n",
        "resultados_baseline"
      ],
      "metadata": {
        "id": "eqeafXu_94Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fc46d1e"
      },
      "source": [
        "## Interpretación de Métricas de Regresión\n",
        "\n",
        "*   **Interpretación:** Mide la magnitud promedio de los errores del modelo. La unidad del RMSE es la misma que la de la variable objetivo (en tu caso, los minutos de retraso). Valores más bajos indican un mejor ajuste del modelo a los datos.\n",
        "*   **¿Qué es un 'buen' valor?** No hay un umbral fijo para un 'buen' RMSE, ya que depende en gran medida del contexto y la escala de tus datos. Sin embargo, un RMSE significativamente menor que la desviación estándar de la variable objetivo suele ser una buena señal. Es una métrica sensible a errores grandes (outliers) debido al cuadrado de los errores.\n",
        "*   **¿Es una buena métrica?** Sí, es ampliamente utilizada. penaliza más los errores grandes, lo que puede ser deseable si los errores grandes son particularmente problemáticos en tu aplicación. Su principal desventaja es que, al ser sensible a outliers, un solo error muy grande puede inflar el RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d181b7b1"
      },
      "source": [
        "### 2. Error Absoluto Medio (MAE - Mean Absolute Error)\n",
        "\n",
        "*   **¿Qué es?** El MAE es el promedio de la magnitud de los errores. A diferencia del RMSE, no eleva al cuadrado los errores, sino que toma su valor absoluto.\n",
        "*   **Interpretación:** También mide la magnitud promedio de los errores del modelo. Su unidad es la misma que la de la variable objetivo. Valores más bajos indican un mejor rendimiento.\n",
        "*   **¿Qué es un 'buen' valor?** Similar al RMSE, depende de la escala de tus datos. Un MAE menor que el rango de tu variable objetivo y, si es posible, menor que un umbral de error aceptable en tu dominio, es deseable.\n",
        "*   **¿Es una buena métrica?** Sí, es otra métrica muy común. Es más robusta a los outliers que el RMSE porque no penaliza los errores grandes de forma cuadrática. Ofrece una interpretación más directa de la magnitud promedio del error en las unidades originales de la variable objetivo. Si prefieres que todos los errores contribuyan por igual a la métrica, MAE es una buena elección."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fb22b3e"
      },
      "source": [
        "### 3. Coeficiente de Determinación (R2 - R-squared)\n",
        "\n",
        "*   **¿Qué es?** El R2 es una medida de la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes. En términos más simples, indica qué tan bien se ajustan las predicciones de tu modelo a los valores reales.\n",
        "*   **Interpretación:** El valor de R2 varía entre 0 y 1 (o puede ser negativo para modelos muy malos, como en tu caso para el baseline).:\n",
        "    *   **R2 = 0:** El modelo no explica ninguna de la variabilidad de la variable objetivo. Las predicciones del modelo no son mejores que simplemente usar el promedio de los valores reales.\n",
        "    *   **R2 = 1:** El modelo explica el 100% de la variabilidad de la variable objetivo. El modelo predice perfectamente los valores reales.\n",
        "    *   **R2 negativo:** Esto sucede cuando el modelo que has ajustado es peor que un modelo que simplemente predice la media de la variable dependiente para todas las observaciones. En tu caso, `R2: -0.0` para el `DummyRegressor` es esperado, ya que este modelo trivial solo predice la media, y la forma en que se calcula R2 lo hace ligeramente negativo si la suma de cuadrados de los residuos es mayor que la suma de cuadrados totales.\n",
        "*   **¿Qué es un 'buen' valor?** En general, cuanto más cercano a 1, mejor. Sin embargo, un R2 alto no siempre significa que el modelo sea práctico, especialmente si se ha sobreajustado a los datos de entrenamiento. Un 'buen' R2 también es contextual y depende de la complejidad del problema. En ciencias sociales, un R2 de 0.3 puede ser considerado bueno, mientras que en física, se esperan valores mucho más altos.\n",
        "*   **¿Es una buena métrica?** Sí, es muy útil para entender la bondad de ajuste global del modelo. La precaución principal es no usarlo como la única métrica, ya que un R2 alto no garantiza un modelo preciso o sin sesgos, y puede ser engañoso en presencia de muchos predictores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ed744a"
      },
      "source": [
        "### Resumen para tus resultados `{'RMSE': 11.8311, 'MAE': 10.2462, 'R2': -0.0}`:\n",
        "\n",
        "Estos resultados son de tu modelo *baseline* (`DummyRegressor`). Un modelo *baseline* es un punto de partida simple y sirve para comparar. Al ser un `DummyRegressor`, es normal que obtengas un R2 muy bajo o negativo, ya que es un modelo muy básico que probablemente predice solo la media de los minutos de retraso. El MAE y RMSE de tu baseline te indican el error promedio de este modelo trivial.\n",
        "\n",
        "Para saber si un futuro modelo es bueno, querrías ver:\n",
        "\n",
        "*   **RMSE y MAE:** Significativamente más bajos que los obtenidos con el modelo *baseline*.\n",
        "*   **R2:** Un valor positivo y, idealmente, cuanto más cercano a 1, mejor (aunque con cautela y comparando con otros modelos)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "def calcular_metricas_regresion(y_test, y_pred):\n",
        "\n",
        "    rmse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    metricas = {\n",
        "        'Raíz del Error Cuadrático Medio': round(rmse, 4),\n",
        "        'Error Absoluto Medio': round(mae, 4),\n",
        "        'R2 Score': round(r2, 4)\n",
        "    }\n",
        "\n",
        "    return metricas"
      ],
      "metadata": {
        "id": "QL38mCZ1D5bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "estrategias = [\"mean\", \"median\", (\"quantile\", 0.25), (\"constant\", 10.0)]\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for estrategia in estrategias:\n",
        "    if isinstance(estrategia, tuple):\n",
        "        estrategia, valor = estrategia\n",
        "        if estrategia == \"quantile\":\n",
        "            model_dummy = DummyRegressor(strategy=estrategia, quantile=valor)\n",
        "        else:\n",
        "            model_dummy = DummyRegressor(strategy=estrategia, constant=valor)\n",
        "    else:\n",
        "        model_dummy = DummyRegressor(strategy=estrategia)\n",
        "\n",
        "    model_dummy.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_dummy = model_dummy.predict(X_test)\n",
        "\n",
        "    metricas = calcular_metricas_regresion(y_test, y_pred_dummy)\n",
        "\n",
        "    resultados[estrategia] = metricas\n",
        "\n",
        "for estrategia, metricas in resultados.items():\n",
        "    print(f\"Estrategia: {estrategia}\")\n",
        "    for metrica, valor in metricas.items():\n",
        "        print(f\"{metrica}: {valor}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "ByOGyoYOCmzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metodo Random Forest"
      ],
      "metadata": {
        "id": "z9b698wZEkgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#los resultados son en minutos; aqui vemos que el modelo generalizó mejor\n",
        "#RMSE= 6.51min, MAE=5.48min, 'R2': 0.6966%\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "modelo= RandomForestRegressor(max_depth=5,random_state=42)\n",
        "modelo.fit(X_train,y_train)\n",
        "y_pred=modelo.predict(X_test)\n",
        "resultados_rf= calcular_regresion(y_test,y_pred)\n",
        "resultados_rf"
      ],
      "metadata": {
        "id": "BwhuOOxQCmwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cross Validation**"
      ],
      "metadata": {
        "id": "M1JK7YHtrQvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold,cross_validate\n",
        "\n",
        "scoring={\n",
        "    \"RMSE\":\"neg_root_mean_squared_error\",\n",
        "    \"MAE\": \"neg_mean_absolute_error\",\n",
        "    \"R2\": \"r2\"\n",
        "}\n",
        "cv= KFold(n_splits=5,shuffle=True,random_state=42)\n",
        "cv_resultados= cross_validate(modelo,X_train,y_train,scoring=scoring,cv=cv)\n",
        "cv_resultados\n"
      ],
      "metadata": {
        "id": "1ZFQE_g8Q96L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.columns)"
      ],
      "metadata": {
        "id": "8MejIGz5esyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.feature_importances_"
      ],
      "metadata": {
        "id": "v5_WDdn4esmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances= modelo.feature_importances_"
      ],
      "metadata": {
        "id": "L_W8sWgze6Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances=pd.DataFrame({\"Features\":X.columns,\"Importances\":(importances*100).round(2)}).sort_values(\"Importances\",ascending=False)\n",
        "feature_importances"
      ],
      "metadata": {
        "id": "DJCBfLRGe6Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados=pd.DataFrame(index=[\"RMSE\",\"MAE\",\"R2\"])\n",
        "model_features=RandomForestRegressor(max_depth=5,random_state=42)\n",
        "ct_features= [i if i !=0 else 1 for i in range(0,17,4)]\n",
        "\n",
        "for i in ct_features:\n",
        "  selected_features= feature_importances[\"Features\"].values[:i]\n",
        "  X_train_sel= X_train[selected_features]\n",
        "  X_test_sel= X_test[selected_features]\n",
        "  model_features.fit(X_train_sel,y_train)\n",
        "  y_pred=model_features.predict(X_test_sel)\n",
        "  metricas=calcular_regresion(y_test,y_pred)\n",
        "  resultados[i]= list(metricas.values())\n",
        "\n",
        "resultados"
      ],
      "metadata": {
        "id": "BV1JpJx8e6G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados=pd.DataFrame(index=[\"RMSE\",\"MAE\",\"R2\"])\n",
        "model_features=RandomForestRegressor(max_depth=5,random_state=42)\n",
        "ct_features=  range(1,5)\n",
        "\n",
        "for i in ct_features:\n",
        "  selected_features= feature_importances[\"Features\"].values[:i]\n",
        "  X_train_sel= X_train[selected_features]\n",
        "  X_test_sel= X_test[selected_features]\n",
        "  model_features.fit(X_train_sel,y_train)\n",
        "  y_pred=model_features.predict(X_test_sel)\n",
        "  metricas=calcular_regresion(y_test,y_pred)\n",
        "  resultados[i]= list(metricas.values())\n",
        "\n",
        "resultados"
      ],
      "metadata": {
        "id": "0vv75EoY0tWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7iR4qGBg0tT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQH7CRF-0tRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#rf= RandomForestClassifier(max_depth = 10, random_state=42)\n",
        "#rf.fit(pd.DataFrame(X_train), y_train)\n",
        "#rf.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "rQsjy2URdCAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "H9REmcfYdise"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Metodo OneHotEnconder**"
      ],
      "metadata": {
        "id": "0nNzgjEn7yV4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfkyj3HD4Bk5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}